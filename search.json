[
  {
    "objectID": "reproducibility.html",
    "href": "reproducibility.html",
    "title": "Reproducibility",
    "section": "",
    "text": "It is good practice to conduct research in an open and reproducible manner, it improves trust in the research output and allows constructive feedback on the approaches taken.\n\n\nOpen scientific research means being transparent about all steps taken in the analysis of data, from reading the raw data in, tidying it (renaming variables and deriving variables) through to running models, estimating parameters and making predictions.\nIdeally work should also aim to adhere to the FAIR Principles and where software is developed, as is the case here where code for analysis is being produced, the FAIR4RS Principles too.\nFAIR means research output is Findable, Accessible, Interoperable and Reusable. To help with this all work should on completion be added to the University of Sheffield Online Research Data Archive (ORDA).\n\n\n\nReproducibility aids transparency and openness of research. By using scripted analysis and embedding code within literate documents we can streamline the work process and provide an accurate record of how we reached our conclusions from the data provided and the methods used. Further by version controlling the development of the scripts throughout their life-cycle we have a record of how the code has changed over time.\nTo aid with this the free open-source software R will be used to undertake data cleaning/preparation, statistical modelling and report writing. It integrates with the open-source scientific publishing system Quarto and as all scripts are based on text files they can be version controlled using Git. We will work collaboratively using the GitHub forge.\nBecause R packages evolve over time as bugs are fixed and new features introduced we will use renv to define a consistent set of packages that are used for analyses.\nGetting setup with R, RStudio and Git/GitHub can be done following the excellent guide Let’s Git started | Happy Git and GitHub for the useR by Jenny Bryan.\n\n\n\nIncluded in this repository is the file references.bib which is a BibTex formatted ASCII text file of citations related to this work. BibTex works well with Quarto and make including citations in work straight-forward (see documentation)."
  },
  {
    "objectID": "reproducibility.html#open-and-reproducible-work",
    "href": "reproducibility.html#open-and-reproducible-work",
    "title": "Reproducibility",
    "section": "",
    "text": "It is good practice to conduct research in an open and reproducible manner, it improves trust in the research output and allows constructive feedback on the approaches taken.\n\n\nOpen scientific research means being transparent about all steps taken in the analysis of data, from reading the raw data in, tidying it (renaming variables and deriving variables) through to running models, estimating parameters and making predictions.\nIdeally work should also aim to adhere to the FAIR Principles and where software is developed, as is the case here where code for analysis is being produced, the FAIR4RS Principles too.\nFAIR means research output is Findable, Accessible, Interoperable and Reusable. To help with this all work should on completion be added to the University of Sheffield Online Research Data Archive (ORDA).\n\n\n\nReproducibility aids transparency and openness of research. By using scripted analysis and embedding code within literate documents we can streamline the work process and provide an accurate record of how we reached our conclusions from the data provided and the methods used. Further by version controlling the development of the scripts throughout their life-cycle we have a record of how the code has changed over time.\nTo aid with this the free open-source software R will be used to undertake data cleaning/preparation, statistical modelling and report writing. It integrates with the open-source scientific publishing system Quarto and as all scripts are based on text files they can be version controlled using Git. We will work collaboratively using the GitHub forge.\nBecause R packages evolve over time as bugs are fixed and new features introduced we will use renv to define a consistent set of packages that are used for analyses.\nGetting setup with R, RStudio and Git/GitHub can be done following the excellent guide Let’s Git started | Happy Git and GitHub for the useR by Jenny Bryan.\n\n\n\nIncluded in this repository is the file references.bib which is a BibTex formatted ASCII text file of citations related to this work. BibTex works well with Quarto and make including citations in work straight-forward (see documentation)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Thyroid Cancer Prediction",
    "section": "",
    "text": "This project details work on the prediction of thyroid cancer.\n\nLiterature\nData Description\nModelling\nCitations\nLinks\n\nThe site is written in Quarto and published via GitHub Pages."
  },
  {
    "objectID": "citations.html",
    "href": "citations.html",
    "title": "Citations",
    "section": "",
    "text": "For BibTeX references see references.bib\n\nCohort Analysis of Clinical and Ultrasound Variables Predicting Cancer Risk in 20,001 Consecutive Thyroid Nodules\nImproving the diagnosis of thyroid cancer by machine learning and clinical data | Scientific Reports\nMcGill Thyroid Nodule Score (MTNS): \"rating the risk,\" a novel predictive scheme for cancer risk determination. - Abstract - Europe PMC\nNomogram for predicting malignancy in thyroid nodules using clinical, biochemical, ultrasonographic, and cytologic features - ScienceDirect\nThe TNAPP web-based algorithm improves thyroid nodule management in clinical practice: A retrospective validation study\nThe FAIR Guiding Principles for scientific data management and stewardship | Scientific Data"
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data Description",
    "section": "",
    "text": "Details of the data set."
  },
  {
    "objectID": "data.html#source",
    "href": "data.html#source",
    "title": "Data Description",
    "section": "Source",
    "text": "Source\nThe data is derived from specialist Thyroid cancer units where patients presenting with symptoms (e.g. nodules) are assessed in greater detail and decisions are made as to whether imaging or further biopsies are required."
  },
  {
    "objectID": "data.html#data",
    "href": "data.html#data",
    "title": "Data Description",
    "section": "Data",
    "text": "Data\nAn ASCII CSV file (Thy3000_DATA_LABELS_Raw.csv) with data on 584 cases has been provided. There is no data dictionary defining what each field is nor its type available yet.\nNB Some of the column headers have commas (,) in the variable names, this can cause problems when reading CSV files. Such strings should be double-quoted which appears to be the case but something to check carefully.\n\n\n\n\n\n\n\n\n\nVariable (as received)\nType\nDescription\nRenamed to…\n\n\n\n\nRecord ID\nstr\nUnique identifier.\nrecord_id\n\n\nData Access Group\nstr\nCenter\ncenter\n\n\nStudy ID\nstr\nStudy Identifiers.\nstudy_id\n\n\n1.1 Date of referral\ndate\nDate of referral\nreferral_date\n\n\n1.2 Which clinic was the patient recruited from?\nstr\nRecruting clinic.\nrecruiting_clinic\n\n\nIf Other\nstr\nOther referring clinic.\n\n\n\n1.3. The date the patient was seen in clinic\ndate\nDate patient was seen in clinic.\nclinc_date\n\n\n1.4 Referral source\nstr\nSource of referral\nreferral_source\n\n\n\"If Other please specify\nstr\nOther referring source\n\n\n\n\"1.4.1 If GP was it 2-week wait referral?\"\n\n\n\n\n\n1.5. Presentation\n\n\n\n\n\nComplete?\n\n\n\n\n\n2.1. Age of the patient when seen in clinic\n\n\n\n\n\n2.2. Body Mass Index of patient\n\n\n\n\n\n2.3. Smoking status\n\n\n\n\n\n2.4. Previous neck irradiation\n\n\n\n\n\n2.5 American Society of Anaesthesiologist (ASA) score\n\n\n\n\n\nComplete?\n\n\n\n\n\n3.1. Presentation (choice=Neck symptoms)\n\n\n\n\n\n3.1. Presentation (choice=Incidental lesion on imaging)\n\n\n\n\n\n3.1. Presentation (choice=HypErthyroidism on thyroid function test)\n\n\n\n\n\n3.1. Presentation (choice=HypOthyroidism on thyroid function test)\n\n\n\n\n\n3.1. Presentation (choice=Symptoms of abnormal thyroid function)\n\n\n\n\n\n3.1. Presentation (choice=Not known)\n\n\n\n\n\n3.1. Presentation (choice=Other)\n\n\n\n\n\nIf other please specify\"\n\n\n\n\n\n3.1.1 Symptomatology (choice=No symptoms)\n\n\n\n\n\n\"3.1.1 Symptomatology (choice=Neck lump (noted by patient family or doctor))\"\n\n\n\n\n\n3.1.1 Symptomatology (choice=Compressive symptoms (breathing or swallowing difficulty or voice change))\n\n\n\n\n\n3.1.1 Symptomatology (choice=Symptoms of thyroid dysfunction)\n\n\n\n\n\n3.1.1 Symptomatology (choice=Other)\n\n\n\n\n\n\"If other please specify\"\n\n\n\n\n\n3.1.2 Was this nodule found incidentally on imaging?\n\n\n\n\n\n\"If yes what imaging\"\n\n\n\n\n\n3.2 Clinical Assessment\n\n\n\n\n\n3.2.1 Retrosternal on clinical examination\n\n\n\n\n\n3.2.2 Palpable lymphadenopathy\n\n\n\n\n\n3.2.3 Patient perception of rapid growth of nodule\n\n\n\n\n\n3.4 Thyroid function tests done within 3 months of presentation to clinic\n\n\n\n\n\n3.5 Ultrasound performed\n\n\n\n\n\n3.5.1 Reported maximum diameter of the largest thyroid nodule on ultrasound in millimetres\n\n\n\n\n\n3.5.2 Description of thyroid nodule(s) on ultrasound\n\n\n\n\n\n\"3.5.3 If Ultrasound performed\n\n\n\n\n\nU stage reported: \"\n\n\n\n\n\n\"3.5.4 If Ultrasound performed\n\n\n\n\n\nTIRADS reported \"\n\n\n\n\n\n\"3.5.5 If Ultrasound performed\n\n\n\n\n\nwas lymphadenopathy documented\"\n\n\n\n\n\n3.5.6 Elastography performed\n\n\n\n\n\n3.5.7 CT neck performed\n\n\n\n\n\n3.5.8 If CT neck performed reason for performing it (choice=Extrathyroid extention/local invasion)\n\n\n\n\n\n3.5.8 If CT neck performed reason for performing it (choice=Retrosternal extension/plan surgical approach)\n\n\n\n\n\n3.5.8 If CT neck performed reason for performing it (choice=Extent of lymphadenopathy)\n\n\n\n\n\n3.5.8 If CT neck performed reason for performing it (choice=Tracheal compression)\n\n\n\n\n\n3.5.8 If CT neck performed reason for performing it (choice=Not known)\n\n\n\n\n\n3.5.8 If CT neck performed reason for performing it (choice=Unrelated to thyroid pathology)\n\n\n\n\n\n3.5.9 MRI neck performed\n\n\n\n\n\n3.5.10 If MRI neck performed reason for performing it (choice=Extrathyroid extention/local invasion)\n\n\n\n\n\n3.5.10 If MRI neck performed reason for performing it (choice=Retrosternal extension/plan surgical approach)\n\n\n\n\n\n3.5.10 If MRI neck performed reason for performing it (choice=Extent of lymphadenopathy)\n\n\n\n\n\n3.5.10 If MRI neck performed reason for performing it (choice=Tracheal compression)\n\n\n\n\n\n3.5.10 If MRI neck performed reason for performing it (choice=Not known)\n\n\n\n\n\n3.5.10 If MRI neck performed reason for performing it (choice=Unrelated to thyroid pathology)\n\n\n\n\n\n3.5.11 Iodine-123 scan performed\n\n\n\n\n\n3.6. FNA of thyroid nodule performed (either at time of ultrasound or later)\n\n\n\n\n\n3.6.1 If FNA performed was Thy or Bethesda stage reported\"\n\n\n\n\n\n3.6.1.1 Thy result\n\n\n\n\n\n3.6.1.2 Bethesda result\n\n\n\n\n\n3.7 Core biopsy performed\n\n\n\n\n\n3.8 FNA of lymph node performed\n\n\n\n\n\n3.8.1 If FNA lymph node performed result\n\n\n\n\n\nComplete?\n\n\n\n\n\n4.1 Initial management decision\n\n\n\n\n\n4.2 Date of decision (either clinic letter or MDT date)\n\n\n\n\n\n4.3 Date of surgery or start of other treatment (if interventional)\n\n\n\n\n\n4.4. In case of no intervention was a routine review offered\n\n\n\n\n\n4.4.1 If yes what was the planned interval (in weeks)\n\n\n\n\n\n4.4.2 Was Ultrasound repeated at routine review?\n\n\n\n\n\n4.4.3 Was FNA repeated at routine review\n\n\n\n\n\n4.4.4 If routine review performed was management strategy changed at review\n\n\n\n\n\n4.4.4.1 If management strategy changed at review revised management decision\n\n\n\n\n\n\"4.4.4.2 If yes reason for change in management\"\n\n\n\n\n\nIf other\n\n\n\n\n\n4.4.4.3 If no change in management decision: date last seen by 'thyroid' team\n\n\n\n\n\n\"4.4.4.4 If no change in management strategy at review\n\n\n\n\n\nconfirm management plan when last seen\"\n\n\n\n\n\n4.4.5 Patient was signposted to appropriate patient SUPPORT organisation and/or provided with written PATIENT information about thyroid nodules (including leaflets)\n\n\n\n\n\nComplete?\n\n\n\n\n\n5.1 Type of thyroid surgery\n\n\n\n\n\n5.1.1 Lymph node dissection done at this surgery\n\n\n\n\n\n5.1.2 Pathology\n\n\n\n\n\n\"If other cancer/other diagnosis please state\"\n\n\n\n\n\nComplete?\n\n\n\n\n\n\nTabular and graphical summaries of the data provided in Thy3000_DATA_LABELS_Raw.csv after cleaning we can summarise the data. In total there were 541 recorded from a total of 13."
  },
  {
    "objectID": "data.html#quantitative-variables",
    "href": "data.html#quantitative-variables",
    "title": "Data Description",
    "section": "Quantitative Variables",
    "text": "Quantitative Variables\n\nStatistics\n\n\n\nSummary statistics for quantitative variables\n\n\nVariable\nMean\nSD\nLower IQR\nMedian\nUpper IQR\nMin\nMax\n\n\n\n\nage\n54.518\n16.683\n42\n54.00\n68.000\n12.0\n91\n\n\nbmi\n27.760\n5.720\n24\n27.05\n30.925\n17.1\n50\n\n\n\n\n\n\n\nAge\n\n\n\n\n\nDistribution of Ages at referral\n\n\n\n\n\n\nBody Mass Index (BMI)\n\n\n\n\n\nDistribution of Body Mass Index (BMI)\n\n\n\n\n\n\nNodule Maximum Diameter\n\n\n\n\n\nDistribution of Nodule Maximum Diameter (mm)"
  },
  {
    "objectID": "data.html#categorical-variables",
    "href": "data.html#categorical-variables",
    "title": "Data Description",
    "section": "Categorical Variables",
    "text": "Categorical Variables\n\nASA Score\n\n\n\n\n\nReported ASA score\n\n\n\n\n\n\n\nReported ASA score\n\n\nasa_score\nn\n%\n\n\n\n\nI\n186\n32.292\n\n\nII\n201\n34.896\n\n\nIII\n70\n12.153\n\n\nIV\n3\n0.521\n\n\nNA\n116\n20.139\n\n\n\n\n\n\n\nData Access Group\n\n\n\n\n\nData Access Group\n\n\n\n\n\n\n\nData Access Group\n\n\ndata_access_group\nn\n%\n\n\n\n\nBarnsley\n35\n6.076\n\n\nCardiff and Vale\n44\n7.639\n\n\nDoncaster\n19\n3.299\n\n\nHull\n31\n5.382\n\n\nNHS Tayside\n30\n5.208\n\n\nNorfolk & Norwich\n30\n5.208\n\n\nPortsmouth\n32\n5.556\n\n\nRoyal Berkshire\n106\n18.403\n\n\nSalford\n40\n6.944\n\n\nSheffield Teaching Hospitals Foundation Trust\n116\n20.139\n\n\nUniversity Hospitals of North Midlands\n56\n9.722\n\n\nWye Valley Trust\n33\n5.729\n\n\nNA\n4\n0.694\n\n\n\n\n\n\n\nReferral Source\n\n\n\n\n\nReferral Source\n\n\n\n\n\n\n\nReferral Source\n\n\nreferral_source\nn\n%\n\n\n\n\nGP\n423\n73.438\n\n\nsecondary care\n149\n25.868\n\n\nNA\n4\n0.694\n\n\n\n\n\n\n\nRecruiting Clinic\n\n\n\n\n\nRecruiting Clinic\n\n\n\n\n\n\n\nRecruiting Clinic\n\n\nclinic_recruiting\nn\n%\n\n\n\n\nENT\n277\n48.090\n\n\nGP\n25\n4.340\n\n\nGeneral surgery (including endocrine surgery)\n127\n22.049\n\n\nJoint thyroid\n75\n13.021\n\n\nMedicine\n58\n10.069\n\n\nOther\n11\n1.910\n\n\nNA\n3\n0.521\n\n\n\n\n\n\n\nThyroid Nodule FNA\n\n\n\n\n\nThyroid Nodule FNA\n\n\n\n\n\n\n\nThyroid Nodule FNA\n\n\nnodule_fna_thy\nn\n%\n\n\n\n\nThy1\n66\n11.458\n\n\nThy2\n113\n19.618\n\n\nThy3\n94\n16.319\n\n\nThy4\n14\n2.431\n\n\nThy5\n14\n2.431\n\n\nNA\n275\n47.743\n\n\n\n\n\n\n\nFinal Pathology\n\n\n\n\n\nFinal Pathology\n\n\n\n\n\n\n\nFinal Pathology\n\n\nfinal_pathology\nn\n%\n\n\n\n\nBenign\n169\n29.340\n\n\nMalignant\n75\n13.021\n\n\nNA\n332\n57.639\n\n\n\n\n\n\n\nFinal Pathology x Thyroid Nodule FNA\nIt is useful to check that the rules we have derived for classifying Final Pathology, which are based on thyroid_surgery_lymph_node_pathology when available and nodule_fna_thy when not are correct. We can do this by tabulating the data (a heatmap could be plotted that graphically shows the data distribution using the geom_tile() geometry).\n\n\n\nSurgical Lymph Node Pathology and Thyroid Nodule FNA. Percentages are by Pathology\n\n\n\n\n\n\n\n\n\n\n\nThyroid Surgery Lymph Node Pathology\nThy1 (%)\nThy2 (%)\nThy3 (%)\nThy4 (%)\nThy5 (%)\nMissing (%)\n\n\n\n\nAnaplastic cancer\nNA\nNA\nNA\nNA\n1 (100.000)\nNA\n\n\nAuto immune thyroiditis\n1 (25.000)\nNA\n1 (25.000)\nNA\nNA\n2 (50.000)\n\n\nColloid adenoma\n1 (16.667)\n1 (16.667)\n2 (33.333)\n1 (16.667)\nNA\n1 (16.667)\n\n\nColloid goitre\n7 (20.000)\n6 (17.143)\n7 (20.000)\nNA\nNA\n15 (42.857)\n\n\nFollicular adenoma\n3 (13.043)\n1 ( 4.348)\n18 (78.261)\n1 ( 4.348)\nNA\nNA\n\n\nFollicular thyroid cancer\n1 ( 7.692)\n1 ( 7.692)\n10 (76.923)\nNA\nNA\n1 ( 7.692)\n\n\nGraves’ disease\n1 (100.000)\nNA\nNA\nNA\nNA\nNA\n\n\nHürthle cell/oncocytic adenoma\n1 (10.000)\n2 (20.000)\n6 (60.000)\n1 (10.000)\nNA\nNA\n\n\nHürthle cell/oncocytic carcinoma\n1 (20.000)\nNA\n3 (60.000)\nNA\n1 (20.000)\nNA\n\n\nMedullary thyroid cancer\nNA\nNA\nNA\n1 (50.000)\nNA\n1 (50.000)\n\n\nOther cancer / Other diagnosis\n2 ( 6.452)\n11 (35.484)\n9 (29.032)\nNA\nNA\n9 (29.032)\n\n\nPapillary thyroid cancer\n5 (10.204)\n4 ( 8.163)\n15 (30.612)\n8 (16.327)\n12 (24.490)\n5 (10.204)\n\n\nSimple cyst\n2 (33.333)\nNA\nNA\nNA\nNA\n4 (66.667)\n\n\nNA\n41 (10.513)\n87 (22.308)\n23 ( 5.897)\n2 ( 0.513)\nNA\n237 (60.769)\n\n\n\n\n\nWe may be interested in the percentages across all observations though.\n\n\n\nSurgical Lymph Node Pathology and Thyroid Nodule FNA. Percentages are across all observations.\n\n\n\n\n\n\n\n\n\n\n\nThyroid Surgery Lymph Node Pathology\nThy1 (%)\nThy2 (%)\nThy3 (%)\nThy4 (%)\nThy5 (%)\nMissing (%)\n\n\n\n\nAnaplastic cancer\nNA\nNA\nNA\nNA\n1 ( 0.174)\nNA\n\n\nAuto immune thyroiditis\n1 ( 0.174)\nNA\n1 ( 0.174)\nNA\nNA\n2 ( 0.347)\n\n\nColloid adenoma\n1 ( 0.174)\n1 ( 0.174)\n2 ( 0.347)\n1 ( 0.174)\nNA\n1 ( 0.174)\n\n\nColloid goitre\n7 ( 1.215)\n6 ( 1.042)\n7 ( 1.215)\nNA\nNA\n15 ( 2.604)\n\n\nFollicular adenoma\n3 ( 0.521)\n1 ( 0.174)\n18 ( 3.125)\n1 ( 0.174)\nNA\nNA\n\n\nFollicular thyroid cancer\n1 ( 0.174)\n1 ( 0.174)\n10 ( 1.736)\nNA\nNA\n1 ( 0.174)\n\n\nGraves’ disease\n1 ( 0.174)\nNA\nNA\nNA\nNA\nNA\n\n\nHürthle cell/oncocytic adenoma\n1 ( 0.174)\n2 ( 0.347)\n6 ( 1.042)\n1 ( 0.174)\nNA\nNA\n\n\nHürthle cell/oncocytic carcinoma\n1 ( 0.174)\nNA\n3 ( 0.521)\nNA\n1 ( 0.174)\nNA\n\n\nMedullary thyroid cancer\nNA\nNA\nNA\n1 ( 0.174)\nNA\n1 ( 0.174)\n\n\nOther cancer / Other diagnosis\n2 ( 0.347)\n11 ( 1.910)\n9 ( 1.562)\nNA\nNA\n9 ( 1.562)\n\n\nPapillary thyroid cancer\n5 ( 0.868)\n4 ( 0.694)\n15 ( 2.604)\n8 ( 1.389)\n12 ( 2.083)\n5 ( 0.868)\n\n\nSimple cyst\n2 ( 0.347)\nNA\nNA\nNA\nNA\n4 ( 0.694)\n\n\nNA\n41 ( 7.118)\n87 (15.104)\n23 ( 3.993)\n2 ( 0.347)\nNA\n237 (41.146)\n\n\n\n\n\nTabulating the Thyroid Nodule FNA against the final prediction\n\n\n\nFinal Pathology and Thyroid Nodule FNA. Percentages are across all observations.\n\n\nNodule FNA\nBenign (%)\nMalignant (%)\nMissing (%)\n\n\n\n\nThy1\n15 ( 2.604)\n8 ( 1.389)\n43 ( 7.465)\n\n\nThy2\n97 (16.840)\n5 ( 0.868)\n11 ( 1.910)\n\n\nThy3\n33 ( 5.729)\n31 ( 5.382)\n30 ( 5.208)\n\n\nThy4\n3 ( 0.521)\n9 ( 1.562)\n2 ( 0.347)\n\n\nThy5\nNA\n14 ( 2.431)\nNA\n\n\nNA\n21 ( 3.646)\n8 ( 1.389)\n246 (42.708)\n\n\n\n\n\nWe can make a stacked Bar chart of this, but first we filter out instances where the final pathology is missing (i.e. NA)"
  },
  {
    "objectID": "modelling.html",
    "href": "modelling.html",
    "title": "Modelling",
    "section": "",
    "text": "The R packages included in the Tidymodels provide an excellent framework for undertaking the modelling aspect of the work.\nA very useful training workshop was held 2023-10-18 as part of the R in Pharma event. Nicola Rennie has made her material is available on-line and it provides a good starting point for applying the various modelling methodologies to prediction of Thyroid cancer.\n\nSlides\nGitHub Repo\n\nWhilst this provides an excellent introduction to the Tidy Modelling framework the book Tidy Modeling with R goes deeper into the methods and options available. Another useful reference on which this books builds is R for Data Science (2e) which should serve as a useful reference for learning R and adopting good practices.\nIt is also recommended to read the documentation that goes with the Tidymodels package, in particular the Get Started page which includes a predictive modelling case study.\n\n\nIn the absence of the data set that is to be analysed we simulate some dummy data on which to demonstrate the methods.\n\n\n\nTo get going with Tidymodels we first need to split our data into Testing and Training subsets. This is done so that we do not have an over-fitted model as we fit the model to the training subset and then test its predictive accuracy in the subset that we withheld, the test subset.\nThe allocation of individuals to train or test is performed randomly and so we set a seed to ensure the pseudo-random number generator produces the same split each and every time this script is run (this makes our work reproducible). A decision has to be made about how to split the data, often a slightly larger proportion is used for the training subset, here we chose to use a 3:1 split (i.e. 75% of observations are used in the training set).\n\nset.seed(5039378)\nsplit &lt;- rsample::initial_split(df_dummy, prop = 0.75)\ntrain &lt;- rsample::training(split)\ntest &lt;- rsample::testing(split)\n\n\n\n\nWe will still want to make some assessment of the model estimated from the training set and this is achieved by resampling which involves taking subsets of our training data and fitting the models on those subsets and then looking at the distribution of metrics across the multiple model fits. A commonly used approach for this methodology is Cross-Validation. V-fold cross-validation splits the data into V folds, the first fold is excluded from the data set and the model assessed, then this subset is replaced and the second fold is excluded and the model assessed again. This is repeated until each fold has been excluded and the model estimated on the remainder. This method can then be repeated R times where the folds are varied in each repetition to give a better estimate of the model parameters.\nThe following figure gives an overview of how V-fold cross-validation works (without repetition).\n\n\n\nV-fold cross-validation of training data. Source: Feature Engineering and Selection: A Practical Approach for Predictive Models\n\n\nWe can set this up by passing the train subset into the rsample::vflod_cv() function and define the number of folds (v) and the number of repeats (repeats).\n\ncv_folds &lt;- rsample::vfold_cv(train, v = 10, repeats = 10)\n\nAnother method of cross-validation is Leave One Out where one observation is removed from the (training) data set, the model is fitted on the remaining samples and then used to make a prediction on the excluded sample. This is then repeated on all samples. We can set this up using the rsample::loo_cv() function.\n\ncv_loo &lt;- rsample::loo_cv(train)\n\n\n\n\nIn the Tidymodels framework the starting point is to create a Recipe, this sets up the “ingredients” for the model and defines what steps should be taken prior to fitting the model, regardless of what model is being fitted. Steps that can go into making a recipe are…\n\nDefine the model in terms of outcome variable and predictors.\nCreating dummy variables for categorical variables.\nNormalizing data, e.g. log-transformation, rescaling.\n\n\nthyroid_recipe &lt;- recipes::recipe(final_pathology ~ gender + age + asa_score + smoking_status + nodule_fna_thy, data = train) |&gt;\n  # recipes::step_num2factor(final_pathology, levels = c(\"Benign\", \"Malignant\")) |&gt;\n  recipes::step_dummy(gender, asa_score, smoking_status, nodule_fna_thy) |&gt;\n  recipes::step_normalize(all_numeric())\n\n\n\n\nOnce a recipe has been defined it can be added to a workflow which will apply this step every time the workflow is run using the different models and post-processing steps that we will add.\n\nthyroid_workflow &lt;- workflows::workflow() |&gt;\n  workflows::add_recipe(thyroid_recipe)"
  },
  {
    "objectID": "modelling.html#tidymodelling",
    "href": "modelling.html#tidymodelling",
    "title": "Modelling",
    "section": "",
    "text": "The R packages included in the Tidymodels provide an excellent framework for undertaking the modelling aspect of the work.\nA very useful training workshop was held 2023-10-18 as part of the R in Pharma event. Nicola Rennie has made her material is available on-line and it provides a good starting point for applying the various modelling methodologies to prediction of Thyroid cancer.\n\nSlides\nGitHub Repo\n\nWhilst this provides an excellent introduction to the Tidy Modelling framework the book Tidy Modeling with R goes deeper into the methods and options available. Another useful reference on which this books builds is R for Data Science (2e) which should serve as a useful reference for learning R and adopting good practices.\nIt is also recommended to read the documentation that goes with the Tidymodels package, in particular the Get Started page which includes a predictive modelling case study.\n\n\nIn the absence of the data set that is to be analysed we simulate some dummy data on which to demonstrate the methods.\n\n\n\nTo get going with Tidymodels we first need to split our data into Testing and Training subsets. This is done so that we do not have an over-fitted model as we fit the model to the training subset and then test its predictive accuracy in the subset that we withheld, the test subset.\nThe allocation of individuals to train or test is performed randomly and so we set a seed to ensure the pseudo-random number generator produces the same split each and every time this script is run (this makes our work reproducible). A decision has to be made about how to split the data, often a slightly larger proportion is used for the training subset, here we chose to use a 3:1 split (i.e. 75% of observations are used in the training set).\n\nset.seed(5039378)\nsplit &lt;- rsample::initial_split(df_dummy, prop = 0.75)\ntrain &lt;- rsample::training(split)\ntest &lt;- rsample::testing(split)\n\n\n\n\nWe will still want to make some assessment of the model estimated from the training set and this is achieved by resampling which involves taking subsets of our training data and fitting the models on those subsets and then looking at the distribution of metrics across the multiple model fits. A commonly used approach for this methodology is Cross-Validation. V-fold cross-validation splits the data into V folds, the first fold is excluded from the data set and the model assessed, then this subset is replaced and the second fold is excluded and the model assessed again. This is repeated until each fold has been excluded and the model estimated on the remainder. This method can then be repeated R times where the folds are varied in each repetition to give a better estimate of the model parameters.\nThe following figure gives an overview of how V-fold cross-validation works (without repetition).\n\n\n\nV-fold cross-validation of training data. Source: Feature Engineering and Selection: A Practical Approach for Predictive Models\n\n\nWe can set this up by passing the train subset into the rsample::vflod_cv() function and define the number of folds (v) and the number of repeats (repeats).\n\ncv_folds &lt;- rsample::vfold_cv(train, v = 10, repeats = 10)\n\nAnother method of cross-validation is Leave One Out where one observation is removed from the (training) data set, the model is fitted on the remaining samples and then used to make a prediction on the excluded sample. This is then repeated on all samples. We can set this up using the rsample::loo_cv() function.\n\ncv_loo &lt;- rsample::loo_cv(train)\n\n\n\n\nIn the Tidymodels framework the starting point is to create a Recipe, this sets up the “ingredients” for the model and defines what steps should be taken prior to fitting the model, regardless of what model is being fitted. Steps that can go into making a recipe are…\n\nDefine the model in terms of outcome variable and predictors.\nCreating dummy variables for categorical variables.\nNormalizing data, e.g. log-transformation, rescaling.\n\n\nthyroid_recipe &lt;- recipes::recipe(final_pathology ~ gender + age + asa_score + smoking_status + nodule_fna_thy, data = train) |&gt;\n  # recipes::step_num2factor(final_pathology, levels = c(\"Benign\", \"Malignant\")) |&gt;\n  recipes::step_dummy(gender, asa_score, smoking_status, nodule_fna_thy) |&gt;\n  recipes::step_normalize(all_numeric())\n\n\n\n\nOnce a recipe has been defined it can be added to a workflow which will apply this step every time the workflow is run using the different models and post-processing steps that we will add.\n\nthyroid_workflow &lt;- workflows::workflow() |&gt;\n  workflows::add_recipe(thyroid_recipe)"
  },
  {
    "objectID": "modelling.html#methods-to-consider",
    "href": "modelling.html#methods-to-consider",
    "title": "Modelling",
    "section": "Methods to Consider",
    "text": "Methods to Consider\nThere are a wealth of options when it comes to “Machine Learning”, these days even logistic regression is grouped into the term! There are however a large number of more sophisticated methods for analysing the data, and it is often wise to apply a number of methods to ensure they are converging on similar solutions rather than cherry-picking any one method.\n\nLogistic Regression\nLogistic regression, even in its most basic form is, still considered a “machine learning” algorithm. However because we do not know which out of an array of variable will be useful predictors and, following Occam’s Razor we would tend to prefer simpler explanatory models over complex ones we need a method of determining what subset of variables gives good prediction. An old approach to this was to use Stepwise regression, perhaps based on univariable analyses to select which to use as a base but these approaches have fallen out favour for various reasons as they are ultimate biased (for an overview see (Steyerberg et al. 2001)).\nA popular alternative is the Least Absolute Shrinkage and Selection Operator (LASSO) proposed by (Tibshirani 1996) which performs L1 regularisation and allows the coefficients for variables in a series of fitted models to “shrink” towards zero but not drop out completely. It is similar to Ridge Regression which avoids over-fitting by reducing the sum of squares of the regression coefficients but unlike Ridge Regression it allows variables to be selected as the coefficients can (almost) drop out by virtue of their coefficients shrinking towards zero.\n\nSpecify the Model\nWhilst we have defined the relationship between variables in the Worfklow above we now need to say what model we wish to use to test the relationship between variables.\nWe first set up a simple logistic regression model using parsnip. The mixture argument is a value 0 &lt;= mixture &lt;= 1 which determines how much L1 regularisation is used in the model. A value of mixture = 1 is equivalent to full L1 regularisation and a LASSO model whilst a value of mixture = 0 is equivalent to ridge regression.\n\ntune_spec_lasso &lt;- parsnip::logistic_reg(penalty = hardhat::tune(), mixture = 1) |&gt;\n  parsnip::set_engine(\"glmnet\")\n\n\n\nTuning\nThe next step is to tune the model using the tune::tune_grid() function which will calculate accuracy or Root Mean Square Error (or other metrics) for a recipe with multiple samples. We defined our resamples above in two forms (not that we defined cross-validation as a way of sampling from our training data above).\n\nlasso_grid &lt;- tune::tune_grid(\n  object = workflows::add_model(thyroid_workflow, tune_spec_lasso),\n  resamples = cv_folds,\n  grid = dials::grid_regular(penalty(), levels = 50)\n)\n\n\n\nFit Final Model\nNow select the model with the highest Receiver Operating Characteristic Area Under the Curve (ROC AUC).\n\nlasso_kfold_roc_auc &lt;- lasso_grid |&gt;\n  tune::select_best(metric = \"roc_auc\")\n\n…and finalize the workflow by adding this value.\n\nfinal_lasso_kfold &lt;- workflows::finalize_workflow(\n  workflows::add_model(thyroid_workflow, tune_spec_lasso),\n  lasso_kfold_roc_auc\n)\n\n\n\nModel Evaluation\nCollect metrics using the original data.\n\ntune::last_fit(object = final_lasso_kfold, split = split) |&gt;\n  tune::collect_metrics()\n\nAnd plot the importance of variables\n\nfinal_lasso_kfold |&gt;\n  fit(train) |&gt;\n  hardhat::extract_fit_parsnip() |&gt;\n  vip::vi(lambda = highest_roc_auc_lasso$penalty) |&gt;\n  dplyr::mutate(\n    Importance = abs(Importance),\n    Variable = fct_reorder(Variable, Importance)\n  ) |&gt;\n  ggplot(mapping = aes(x = Importance, y = Variable, fill = Sign)) +\n  geom_col()\n\n\n\n\nRandom Forest\nRandom forests build on the concept of regression trees by building many such trees on random subsets of data and averaging them. They build “deep” trees partitioning each time until all individuals are classified, part of the art is deciding how “deep” to go as too many partitions results in over-fitting and lack of generalisability. It is in this regard an “ensemble” method as it is averaging across many possible methods.\n\n\nGradient Boosting\nGradient Boosting is another “ensemble” method but in contrast to Random Forests where deep partitioning trees are formed, gradient boosting uses “shallow” trees with simpler decision rules and layers are built in a stage-wise fashion. It allows a choice of loss functions for optimisation and typically out-performs Random Forests when it comes to prediction modelling.\n\n\nSupport Vector Machine"
  },
  {
    "objectID": "modelling.html#model-assessment",
    "href": "modelling.html#model-assessment",
    "title": "Modelling",
    "section": "Model Assessment",
    "text": "Model Assessment\nWhen considering the utility of prediction there are a number of metrics that can be used to determine how useful a model is. These focus on a number of terms which have very specific statistical meaning such as Sensitivity and Specificity.\n\n\n\n\nTest Positive\nTest Negative\n\n\n\n\nActual Positive\nTrue Positive (TP)\nFalse Negative (FN)\n\n\nActual Negative\nFalse Positive (FP)\nTrue Negative (TN)\n\n\n\nThere are a wealth of metrics based on combinations of these True/False Positive/Negative including precision, recall and so forth (refer to the above linked article for further details).\n\nReceiver Operating Characteristics\nThe Receiver Operating Characteristic (ROC) is a useful graphical tool for potting the false positive rate v’s the true positive rate (sensitivity)."
  },
  {
    "objectID": "modelling.html#references",
    "href": "modelling.html#references",
    "title": "Modelling",
    "section": "References",
    "text": "References\n\n\nSteyerberg, Ewout W., Marinus J. C. Eijkemans, Frank E. Harrell, and J. Dik F. Habbema. 2001. “Prognostic Modeling with Logistic Regression Analysis: In Search of a Sensible Strategy in Small Data Sets.” Med. Decis. Making 21 (1): 45–56. https://doi.org/10.1177/0272989X0102100106.\n\n\nTibshirani, Robert. 1996. “Regression Shrinkage and Selection via the Lasso.” Journal of the Royal Statistical Society. Series B (Methodological) 58 (1): 267–88. https://doi.org/10.2307/2346178."
  },
  {
    "objectID": "literature.html",
    "href": "literature.html",
    "title": "Literature",
    "section": "",
    "text": "Reviews of the existing literature around predictive modelling of Thyroid cancer are detailed below."
  },
  {
    "objectID": "literature.html#improving-the-diagnosis-of-thyroid-cancer-by-machine-learning-and-clinical-data",
    "href": "literature.html#improving-the-diagnosis-of-thyroid-cancer-by-machine-learning-and-clinical-data",
    "title": "Literature",
    "section": "Improving the diagnosis of thyroid cancer by machine learning and clinical data",
    "text": "Improving the diagnosis of thyroid cancer by machine learning and clinical data\nUsed a range of models (logistic regression, gradient boosting, linear discriminant analysis, support vector machine and random forest) to predict malignancy based on 18 predictor variables. Assessed via accuracy, precision, sensitivity and specificity and Area Under the Recevier Operating Characteristic (ROC).\n\nMethods\n10-fold cross validation (splitting data into ten subsets)\n\n\nPerformance\n\n\n\n\n\n\n\n\n\n\n\nModel\nAccuracy\nAUROC\nSensitivity\nSpecificity\nPrecision\n\n\n\n\nGBM\n0.7741\n0.8497\n0.8750\n0.5741\n0.8029\n\n\nLogistic\n0.7834\n0.8422\n0.8352\n0.6806\n0.8384\n\n\nLDA\n0.7790\n0.8394\n0.8452\n0.6477\n0.8263\n\n\nSVM (Radial)\n0.7688\n0.8237\n0.8435\n0.6206\n0.8149\n\n\nSVM (Linear)\n0.7661\n0.8200\n0.8322\n0.6349\n0.8186\n\n\nRandom Forest\n0.7931\n0.8541\n0.8629\n0.6547\n0.8321\n\n\n\nTable 2\n\n\n\nFigure 3\n\n\n\n\nVariable Importance\nInteresting approach using permutation prediction importance.\nSix most important variables are shown in table 6 and are all features of the nodules, no other biological features such as gender or age.\n\n\n\nFigure 4"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This work is being undertaken by Ovie Edafe as part of a PhD under the supervision of Karen Sisley and Sabapathy Balasubramanian at The University of Sheffield and in collaboration with Neil Shephard."
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "Links",
    "section": "",
    "text": "Thyroid Nodule App"
  },
  {
    "objectID": "links.html#thyroid-prediction-tools",
    "href": "links.html#thyroid-prediction-tools",
    "title": "Links",
    "section": "",
    "text": "Thyroid Nodule App"
  },
  {
    "objectID": "links.html#software",
    "href": "links.html#software",
    "title": "Links",
    "section": "Software",
    "text": "Software\n\nR\nRStudio\nQuarto\nLet’s Git started | Happy Git and GitHub for the useR\nR for Data Science (2e)\nTidy Modeling with R\nR for Non-Programmers: A Guide for Social Scientists"
  }
]